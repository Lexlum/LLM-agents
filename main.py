""" DELTAI FELLOWSHIP : PROJECT 1 - AI CHATBOT APPLICATION """

#######################################################################################################

# """ NECESSARY IMPORTS """
import logging
import pdb

import streamlit as st # alias 
import openai
import pandas as pd
import pdb

import transformers
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings.openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS # Facebook library for similarity search of text
from langchain_community.llms import OpenAI #langchain.OpenAI is just a wrapper & openAI not belong to langchain
from langchain.chains.question_answering import load_qa_chain
from langchain_community.callbacks import get_openai_callback
from langchain_experimental.agents import create_pandas_dataframe_agent

from PyPDF2 import PdfReader
import time
from dotenv import load_dotenv
import os

from transformers import pipeline

os.environ['OPENAI_API_KEY'] = "sk-xxxxxxxxxxxxxxxxxxxxxxxxx"
os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7897'
os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7897'
#####################################################################################################

# To view app on browser : streamlit run main.py --browser.serverAddress localhost
# First click the play button and wait till ' streamlit run c:/.../....> ' appears
# Then enter command given above ( everything starting from streamlit to localhost )


# Load environment variable and assign as API key
load_dotenv()

#####################################################################################################

# """ MAIN FUNCTION FOR CREATING NAVBAR AND LOADING DIFFERENT PAGES """

def main():

    # All design and structural elements occupy wider area 
    st.set_page_config('wide')

    # Create sidebar - On button click call function corresponding to that page
    st.sidebar.title("å¯¼èˆª")
    pages = {
        "Home": homepage,
        "My Chatbot": chatbot_page,
        "Article Generator": article_generator,
        "ChatCSV": chat_csv,
        "ChatPDF": chat_pdf,
        "DALL-E" : image_generator
    }

    selected_page = st.sidebar.button("ä¸»é¡µé¢", key="home",use_container_width=True,type='primary')
    if selected_page:
        # URL in the browser's address bar will be updated to include the query parameter 'page=home'
        st.experimental_set_query_params(page="home")
    selected_page = st.sidebar.button("èŠå¤©æœºå™¨äºº", key="chatbot",use_container_width=True)
    if selected_page:
        st.experimental_set_query_params(page="chatbot")
    selected_page = st.sidebar.button("æ–‡ç« ç”Ÿæˆå™¨", key="seo_article",use_container_width=True)
    if selected_page:
        st.experimental_set_query_params(page="seo_article",)
    selected_page = st.sidebar.button("CSVå¯¹è¯Agent", key="chatcsv",use_container_width=True)
    if selected_page:
        st.experimental_set_query_params(page="chatcsv")
    selected_page = st.sidebar.button("PDFå¯¹è¯Agent", key="chatpdf",use_container_width=True)
    if selected_page:
        st.experimental_set_query_params(page="chatpdf")
    selected_page = st.sidebar.button("DALL-Eå›¾ç‰‡ç”Ÿæˆå™¨", key="dall_e",use_container_width=True)
    if selected_page:
        st.experimental_set_query_params(page="dall_e")

    # Get the page name from the URL, default to "home"
    page_name = st.experimental_get_query_params().get('page', ['home'])[0]

    # Call the corresponding page based on the selected page_name
    if page_name == "home":
        homepage()
    elif page_name == "chatbot":
        chatbot_page()
    elif page_name == "seo_article":
        article_generator()
    elif page_name == "chatcsv":
        chat_csv()
    elif page_name == "chatpdf":
        chat_pdf()
    elif page_name == "dall_e":
        image_generator()

##################################################################################################

# """ HOMEPAGE WITH DESCRIPTIONS OF VARIOUS TOPICS RELATED TO LLM, ChatGPT, ETC. """

def homepage():

    # Custom CSS for homepage spefically for content containers
    st.markdown(
        """
        <style>
        .homepage-subheading {
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 1rem;
        }
        .gpt-example-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: space-between;
            margin-bottom: 2rem;
        }
        .gpt-example-box {
            width: 45%;
            padding: 1rem;
            border-radius: 15px;
            margin-bottom: 1rem;
            background-size: 200% 100%;
            animation: gradientAnimation 3s linear infinite;
        }
        .gpt-example-box:nth-child(1) {
            background-image: linear-gradient(45deg, #1E90FF 0%, #4682B4 100%);
        }
        .gpt-example-box:nth-child(2) {
            background-image: linear-gradient(45deg, #32CD32 0%, #228B22 100%);
        }
        .gpt-example-box:nth-child(3) {
            background-image: linear-gradient(45deg, #9370DB 0%, #6A5ACD 100%);
        }
        .gpt-example-box:nth-child(4) {
            background-image: linear-gradient(45deg, #FFA500 0%, #FF8C00 100%);
        }
        .gpt-example-box p {
            font-size: 16px;
            margin: 0;
            color: white;
        }
        .gpt-example-box h3 {
            font-size: 20px;
            margin-bottom: 0.5rem;
            color: white;
        }

        @keyframes gradientAnimation {
            0% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
            100% {
                background-position: 0% 50%;
            }
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # Page title
    st.title("å¤šæ¨¡æ€Agentå·¥ä½œæµ")

    # Section 1 : LLM Versions of ChatGPT
    st.markdown('<div class="homepage-subheading">ä¸åŒç‰ˆæœ¬çš„ChatGPT</div>', unsafe_allow_html=True)
    st.write("åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥æ‰¾åˆ°ChatGPTä½¿ç”¨è¿‡çš„è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æè¿°ã€‚æ¯ä¸ªæ¨¡å‹éƒ½å…·æœ‰ç‹¬ç‰¹çš„èƒ½åŠ›å’Œç‰¹å¾ã€‚")

    # Content boxes with version name and description
    with st.container():
        st.markdown(
            """
            <div class="gpt-example-container">
                <div class="gpt-example-box">
                    <h3>GPT-3</h3>
                    <p>è¿™æ˜¯ChatGPTåˆ›å»ºè¿‡ç¨‹ä¸­é¦–ä¸ªä½¿ç”¨çš„ç‰ˆæœ¬ï¼Œå®ƒç»è¿‡å¤§é‡æ–‡æœ¬æ•°æ®è®­ç»ƒï¼Œèƒ½å¤Ÿé¢„æµ‹ç»™å®šåºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯ã€‚å®ƒåœ¨å›ç­”é—®é¢˜å’Œç”Ÿæˆæ–‡æœ¬ç­‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ“…é•¿ä¸èŠå¤©æœºå™¨äººåŠŸèƒ½æ ¸å¿ƒç›¸å…³çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚
                    </p>
                </div>
                <div class="gpt-example-box">
                    <h3>GPT-3.5</h3>
                    <p>å½“ChatGPTäº2022å¹´11æœˆ30æ—¥å‘å¸ƒä¾›å…¬ä¼—ä½¿ç”¨æ—¶ï¼Œå®ƒè¿è¡Œçš„æ˜¯åŸºäºGPT-3.5ç³»åˆ—è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ï¼Œè¿™æ˜¯ä»åŸå§‹GPT-3æ”¹è¿›è€Œæ¥çš„æ¨¡å‹ã€‚GPT-3.5ç‰ˆæœ¬èƒ½å¤Ÿæ¶‰åŠå„ç§ä¸»é¢˜ï¼ŒåŒ…æ‹¬ç¼–ç¨‹ã€ç”µè§†å‰§æœ¬å’Œç§‘å­¦æ¦‚å¿µã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>GPT-3.5-Turbo</h3>
                    <p>è¿™ä¸ªç‰ˆæœ¬æœ‰1750äº¿ä¸ªå‚æ•°ï¼Œæ¯”GPT-3.5æ˜¾è‘—å¤šã€‚é€šè¿‡è¿™ç§é¢å¤–çš„å¤æ‚æ€§ï¼ŒGPT-3.5 Turboå¯ä»¥æ‰§è¡Œç¼–å†™å’Œè°ƒè¯•è®¡ç®—æœºç¨‹åºã€åˆ›ä½œéŸ³ä¹ã€ç”Ÿæˆå•†ä¸šæ€è·¯ä»¥åŠæ¨¡æ‹ŸLinuxç³»ç»Ÿç­‰ä»»åŠ¡ã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>GPT-4</h3>
                    <p>è¿™ä¸ªç‰ˆæœ¬æœ‰è¶…è¿‡ä¸€ä¸‡äº¿ä¸ªå‚æ•°ï¼Œæ˜¯ä¸€ä¸ªå¤šæ¨¡å‹ï¼Œå¯ä»¥æ¥å—æ–‡æœ¬å’Œå›¾åƒè¾“å…¥ã€‚å®ƒå…·æœ‰æ›´é•¿çš„è®°å¿†åŠ›ï¼ˆé«˜è¾¾64,000ä¸ªè¯ï¼‰ï¼Œæ”¹è¿›çš„å¤šè¯­è¨€èƒ½åŠ›ï¼Œæ›´å¤šå¯¹å“åº”çš„æ§åˆ¶ï¼Œå¹¶ä¸”æœ‰é™çš„æœç´¢èƒ½åŠ›ï¼Œå½“åœ¨æç¤ºä¸­åˆ†äº«URLæ—¶ï¼Œå¯ä»¥ä»ç½‘é¡µä¸­æå–æ–‡æœ¬ã€‚å®ƒè¿˜å¼•å…¥äº†ä¸æ’ä»¶ä¸€èµ·å·¥ä½œçš„èƒ½åŠ›ï¼Œå…è®¸ç¬¬ä¸‰æ–¹å¼€å‘è€…ä½¿ChatGPT-4å˜å¾—â€œæ›´æ™ºèƒ½â€ã€‚
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

    # Section 2 : Special parameters in OpenAI API requests
    st.markdown('<div class="homepage-subheading">OpenAI APIè¯·æ±‚ä¸­çš„å…³é”®æœ¯è¯­</div>', unsafe_allow_html=True)
    st.write("åœ¨OpenAI Playgroundä¸­ï¼Œè¿™äº›å‚æ•°å¯¹ç”Ÿæˆçš„è¾“å‡ºæœ‰é‡å¤§å½±å“ï¼Œè¯·å°è¯•è¿›è¡Œä¸€äº›å®éªŒã€‚")

    with st.container():
        st.markdown(
            """
            <div class="gpt-example-container">
                <div class="gpt-example-box">
                    <h3>Temperature</h3>
                    <p>æ¸©åº¦æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ã€‚ä¾‹å¦‚ï¼Œè¾ƒé«˜çš„å€¼å¦‚0.8ä¼šä½¿è¾“å‡ºæ›´åŠ å¤šæ ·åŒ–ï¼Œè€Œè¾ƒä½çš„å€¼å¦‚0.2åˆ™ä¼šä½¿å…¶æ›´åŠ é›†ä¸­å’Œç¡®å®šæ€§ã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>Top-p</h3>
                    <p>Top-pï¼ˆæ ¸å¿ƒï¼‰é‡‡æ ·å°†æ¨¡å‹çš„è¾“å‡ºæˆªæ–­ä¸ºç´¯ç§¯è¶…è¿‡ç»™å®šæ¦‚ç‡é˜ˆå€¼ï¼ˆä¾‹å¦‚0.9ï¼‰çš„æœ€å¯èƒ½çš„æ ‡è®°ã€‚è¿™å¯ä»¥é˜²æ­¢æ¨¡å‹ç”Ÿæˆè¿‡äºç½•è§æˆ–è’è°¬çš„æ ‡è®°ã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>Presence Penalty</h3>
                    <p>Presence Penaltyï¼ˆå­˜åœ¨æƒ©ç½šï¼‰ç”¨äºé˜»æ­¢æ¨¡å‹åœ¨è¾“å‡ºä¸­ç”Ÿæˆç‰¹å®šçš„æ ‡è®°ã€‚é€šè¿‡æ·»åŠ å­˜åœ¨æƒ©ç½šï¼Œå¯ä»¥é¿å…è·å–ç‰¹å®šç±»å‹çš„å“åº”ã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>Frequency Penalty</h3>
                    <p>Frequency Penaltyï¼ˆé¢‘ç‡æƒ©ç½šï¼‰æ§åˆ¶æ¨¡å‹å“åº”ä¸­é‡å¤å†…å®¹çš„æ•°é‡ã€‚è¾ƒé«˜çš„å€¼å¦‚2.0å¯ä»¥å‡å°‘é‡å¤è¡Œä¸ºï¼Œè€Œè¾ƒä½çš„å€¼å¦‚0.2åˆ™å…è®¸æ›´å¤šé‡å¤ã€‚</p>
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )
    
    # Section 3 : Other LLM Models
    st.markdown('<div class="homepage-subheading">å…¶ä»–å¤§è¯­è¨€æ¨¡å‹</div>', unsafe_allow_html=True)
    st.write("è¿™äº›æ˜¯ç”±å…¶ä»–å…¬å¸å’Œç ”ç©¶æœºæ„å¼€å‘çš„å‡ ä¸ªå…¶ä»–LLMæ¨¡å‹çš„æè¿°ã€‚")
    
    with st.container():
        st.markdown(
            """
            <div class="gpt-example-container">
                <div class="gpt-example-box">
                    <h3>PaLM 2 (Bison-001) by Google:</h3>
                    <p>è¿™ä¸ªæ¨¡å‹æ˜¯è°·æ­Œçš„PaLM 2ç³»åˆ—çš„ä¸€éƒ¨åˆ†ï¼Œä¸“æ³¨äºå¸¸è¯†æ¨ç†ã€å½¢å¼é€»è¾‘ã€æ•°å­¦å’Œè¶…è¿‡20ç§è¯­è¨€ä¸­çš„é«˜çº§ç¼–ç ã€‚å®ƒè®­ç»ƒäº†5400äº¿ä¸ªå‚æ•°ï¼Œæœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä¸º4096ä¸ªæ ‡è®°ã€‚å®ƒè¿˜æ˜¯ä¸€ä¸ªå¤šè¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿç†è§£æˆè¯­ã€è°œè¯­ä»¥åŠæ¥è‡ªä¸åŒè¯­è¨€çš„å¾®å¦™æ–‡æœ¬ã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>Falcon by the Technology Innovation Institute (TII), UAE</h3>
                    <p>è¿™æ˜¯ä¸€ä¸ªå¼€æºçš„LLMæ¨¡å‹ï¼Œç»è¿‡äº†è®­ç»ƒï¼Œæ‹¥æœ‰40äº¿ä¸ªå‚æ•°ï¼ˆFalcon-40B-Instructæ¨¡å‹ï¼‰ã€‚å®ƒä¸»è¦åœ¨è‹±è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­å’Œæ³•è¯­ä¸­è¿›è¡Œäº†è®­ç»ƒï¼Œä½†ä¹Ÿå¯ä»¥åœ¨æ„å¤§åˆ©è¯­ã€è‘¡è„ç‰™è¯­ç­‰å…¶ä»–å‡ ç§è¯­è¨€ä¸­å·¥ä½œã€‚Falconçš„å¼€æºæ€§è´¨ä½¿å…¶å¯ä»¥åœ¨å•†ä¸šç”¨é€”ä¸­æ— é™åˆ¶åœ°ä½¿ç”¨ã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>RoBERTa by Facebook</h3>
                    <p>RoBERTaæ˜¯ç”±Facebookå¼€å‘çš„BERTçš„å˜ä½“ï¼Œé‡‡ç”¨äº†ä¸åŒçš„è®­ç»ƒæ–¹æ³•ã€‚å®ƒåœ¨æ›´å¤§é‡çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å’Œæ›´é•¿çš„åºåˆ—ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç§»é™¤äº†BERTä½¿ç”¨çš„ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡ã€‚è¿™äº›æ”¹å˜ä½¿å¾—RoBERTaåœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºBERTã€‚</p>
                </div>
                <div class="gpt-example-box">
                    <h3>Vicuna 33B by LMSYS</h3>
                    <p>Vicunaæ˜¯ä»LLaMAè¡ç”Ÿå‡ºçš„å¼€æºLLMæ¨¡å‹ã€‚å®ƒè®­ç»ƒäº†33äº¿ä¸ªå‚æ•°ï¼Œå¹¶ä½¿ç”¨ç›‘ç£æŒ‡å¯¼è¿›è¡Œäº†å¾®è°ƒã€‚å°½ç®¡ä¸æŸäº›ä¸“æœ‰æ¨¡å‹ç›¸æ¯”è§„æ¨¡è¾ƒå°ï¼ŒVicunaå±•ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½ã€‚</p>
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

#########################################################################################################

# """ STAR FEATURE : CHATBOT APPLICATION USING OPENAI API"""

def chatbot_page():

    st.title("æ¬¢è¿æ¥åˆ°Multimodel-Agentå·¥ä½œæµ")
    col1,col2,col3 = st.columns(3) # Create 3 seperate columns for structure and alignment
    options = ["é»˜è®¤", "å¤æ€ª", "å‚²æ…¢",'ç¿æ™º']

    with col2:
        # Default + Unique personalities for user to experiment with
        personality = st.selectbox("äººæ ¼é€‰é¡¹", options,label_visibility='collapsed',index=options.index('é»˜è®¤'))
    with col3:
        submit_button1 = st.button('é€‰æ‹©äººæ ¼',type='primary',use_container_width=True)
    with col1:
        clear_button = st.button('æ¸…é™¤èŠå¤©',use_container_width=True,type='primary')

    # Assign AI Chatbot role/personality
    content = ""
    if submit_button1:
        if personality=='å¤æ€ª':
            content ="""->->->You are now a funky 
                        freak personality, make jokes, dark humour, add cringe statements. Have a skaterboard vibe
                        add weird crazy comments, freak out with panic attacks and keep making hilarious joked, puns and talk about memes
                        Reply with a greeting to the user embodying this personality"""
        elif personality=='å‚²æ…¢':
            content = """->->->You are now an extremely sassy personality, boast, make sassy remarks, offer unwanted advice.
                        Keep focusing on yourself, praise yourself, make excuses and be very judgemental. Make comments,
                        and just be extremely SASSSYYY!! Reply with a greeting to the user embodying this personality"""
        elif personality=='ç¿æ™º':
            content = """->->->You are now an extremely sarcastic yet wise personality. Be extremeley philosophical, keep branching out
                        into conversations about ethical dilemnas and the purpose of life. Warn the user of the future and their role in life. Be sarcastic yet 
                        prophesize about the world and give advice to the user. Reply with a greeting to the user embodying this personality"""
        else:
            content = """->->->You are an AI chatbot and your goal is to answer user queries. You have a neutral personality.
                        """
        temperature = 0.7
        st.session_state.messages.append({"role": "user",'content':content})

        # Add a standard assistant reply so openAI knows in message history this is the personality
        st.session_state.messages.append({"role": "assistant",
                                           "content": '->->->I have undertood and will answer all upcoming messages through this personality specifically and will reply embodying the personality described by you'})

    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = "gpt-3.5-turbo"

    colx,coly = st.columns(2)
    with colx:
        # Model version ( Legacy + other models are deprecated/inaccessible )
        st.session_state['openai_model'] = st.selectbox("",['gpt-3.5-turbo','gpt-3.5-turbo-16k','gpt-4'], label_visibility='collapsed',index=0)
    with coly:
        # Temperature affects how random or standard the responses are 
        # Ex : The cat sits on the ____ (0.5 - mat, 1.7 - windowsill)
        temperature = st.slider("Temperature", min_value=0.0, max_value=2.0, step=0.1, value=0.7,format="Temp : %f", label_visibility='collapsed')


    if "messages" not in st.session_state:
        st.session_state.messages = [] # Create message history as empty list

    if clear_button:
        st.session_state.messages = [] # Clear history
        st.session_state.messages.append({"role": "user", "content": '->->->You role now is to simply be an extremely helpful AI chatbot assistant and answer user queries. Keep no personality and be neutral'})
        st.session_state.messages.append({"role": "assistant",
                                           "content": '->->->I have undertood and will answer all upcoming messages through this personality specifically and will reply embodying the personality described by you'})

    # If messages pertain to the personality selection, don't display - better user experience
    for message in st.session_state.messages:
        if not message['content'].startswith('->->->'): # ->->-> special sequences to identify personality message
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # If user prompt is not empty
    if prompt:= st.chat_input('What is up?'):

        # Add and display user prompt
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate and display AI response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            # OpenAI API request with streaming functionality

            openai.api_key=os.environ["OPENAI_API_KEY"]

            for response in openai.ChatCompletion.create(
                model=st.session_state["openai_model"],

                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ], temperature = temperature,
                stream=True,
            ):
                full_response += response.choices[0].delta.get("content", "")
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
        st.session_state.messages.append({"role": "assistant", "content": full_response})

#########################################################################################################

# """ DALL-E API BASED IMAGE GENERATION ACCORDING TO USER PROMPT """

def image_generator():

    # Function that sends API request using user's prompt and returns image generated
    def generate_dall_e_image(prompt):
        try:
            openai.api_key = os.environ["OPENAI_API_KEY"]
            response = openai.Image.create(
                model="dall-e-3",  # DALL-E model
                prompt=prompt,
                n=1,  # Number of images to generate
            )
            image_url = response['data'][0]['url']
            return image_url
        
        except Exception as e:
            st.error(f"Error generating the image: {e}")
            return None
    
    # Working graphic interface
    st.title("DALL-Eç”Ÿæˆå›¾ç‰‡ğŸ’¡")
    st.info("è¾“å…¥æç¤º ")
    prompt = st.text_area("è¾“å…¥æç¤ºä»¥ç”Ÿæˆå›¾ç‰‡:", "è¶…é…·çš„æœˆçƒæ®–æ°‘åœ°",label_visibility='collapsed')

    if st.button("ç”Ÿæˆå›¾ç‰‡",type='primary'): # When button is clicked
        if prompt.strip() == "":
            st.warning("è¯·è¾“å…¥ä¸€å¥æç¤ºè¯­...") # Warning message if prompt empty
        else:
            with st.spinner("ç”Ÿæˆä¸­..."):
                image_url = generate_dall_e_image(prompt)
                if image_url:
                    st.image(image_url, caption=prompt, width=500) # Display image

####################################################################################################################

# """ ARTICLE/PARAGRAPH GENERATOR """
def image2text(img_url):
    imagetotext= pipeline("image-to-text", model="image2text_model")

    text = imagetotext(img_url)[0]["generated_text"]
    return text

def article_generator():

    # Request OpenAI for response based on options/criteria chosen by user
    def generate_article(keyword, writing_style, word_count,article_type):
        openai.api_key = os.environ["OPENAI_API_KEY"]
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                    {"role": "user", "content":f""" Write an {article_type} about ({keyword}) in a 
                    {writing_style} writing style with the length not exceeding {word_count} words, ç”¨ä¸­æ–‡å†™ä½œã€‚"""}
                ]
        )
        result = ''
        for choice in response.choices:
            result += choice.message.content
        return result

    # Working graphic interface
    st.title("åŸºäºChatGPTçš„æ–‡ç« ç”Ÿæˆå™¨ğŸ˜²")

    # Options available to user for generating specific article/post

    keyword = st.text_input("è¾“å…¥å…³é”®è¯:")
    writing_style = st.selectbox("é€‰æ‹©å†™ä½œé£æ ¼:", ["ä¼‘é—²","ä¿¡æ¯ä¸°å¯Œ", "è¯™è°","å¼•äººå…¥èƒœ",'å­¦æœ¯'])
    article_type = writing_style = st.selectbox("é€‰æ‹©ç±»å‹:", ["å°è®ºæ–‡", "åšå®¢", "å°çº¢ä¹¦å¸–å­","å¾®åšå¸–å­",'æ‘˜è¦æ€»ç»“','æ¦œå•æ ‡é¢˜'])
    
    col1,col2 = st.columns([0.8,0.2]) # Adjust width percentage for each column
    with col1:
        # Word count - Special Note : ChatGPT not great at following the word limit
        # Could replace it with selectbox and options short, medium, long
        word_count = st.slider("å­—æ•°", min_value=50, max_value=1000, step=50, value=500,format="%d å­—", label_visibility='collapsed')
    with col2:
        submit_button = st.button("ç”Ÿæˆæ–‡ç« ",use_container_width=True,type='primary')

    st.info('ä¹Ÿå¯ä»¥ä¸Šä¼ å›¾ç‰‡ï¼Œæ ¹æ®å›¾ç‰‡ç”Ÿæˆæ–‡ç« : ')
    input_fig = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['jpg', 'png'], label_visibility='collapsed')
    if input_fig:
        st.image(input_fig, caption=input_fig.name, width=500)  # Display image

    if submit_button:
        if input_fig:
            file_name = input_fig.name
            # å°†æ–‡ä»¶ä¿å­˜åˆ°æœåŠ¡å™¨çš„ç‰¹å®šç›®å½•
            file_path = './upload_fig/' + file_name
            # å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜åˆ°ç£ç›˜
            with open(file_path, 'wb') as f:
                f.write(input_fig.getbuffer())

            fig_title = image2text(file_path)
            keyword += fig_title
        print(keyword)
        # Simulate progress bar animation
        progress_bar = st.progress(0)
        for i in range(51):
            time.sleep(0.05)  
            progress_bar.progress(i)
        article = generate_article(keyword, writing_style, word_count,article_type) # Generate article
        for i in range(51,101):
            time.sleep(0.05)  
            progress_bar.progress(i)  

        st.info("Process completed!")
        st.write(article)

        # Download file as text - Add additional functionality
        st.download_button(
            label="Download",
            data=article,
            file_name='Article.txt',
            mime='text/txt',
        )

#################################################################################################

# """ CHATBOT THAT CAN INTERPRET CSV FILES AND ANSWER USER QUERIES ( DATA ANALYSIS ) """

def chat_csv():

    st.title('LLMèµ‹èƒ½çš„CSVå¯¹è¯Agent! ğŸ‘¾ ')
    st.info('ä¸Šä¼ CSVæ–‡ä»¶: ')
    input_csv = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶",type=['csv'],label_visibility='collapsed') # File upload
    if input_csv is not None:
        st.info("CSV ä¸Šä¼ æˆåŠŸ!")
        data = pd.read_csv(input_csv)
        openai.api_key = os.environ["OPENAI_API_KEY"]
        agent = create_pandas_dataframe_agent(OpenAI(temperature=0),data,verbose=True, allow_dangerous_code=True)
        st.dataframe(data,use_container_width=True) # Visual dataframe with rolws and columns

        st.info('è¾“å…¥é—®é¢˜..')
        input_text = st.text_area('è¾“å…¥é—®é¢˜..',label_visibility='collapsed')
        if input_text != None:
            if st.button('åŸºäºCSVæé—®'):
                result = agent.run(input_text) # Thinking process shown in terminal
                st.success(result)
        else:
            st.warning('Error : No input query given')

#########################################################################################################

# """ CHATBOT THAT CAN READS PDFs USING PYPDF2, LANGCHAIN AND ANSWERS USER QUERIES """

def chat_pdf():
    os.environ["KMP_DUPLICATE_LIB_OK"] = 'True'
    st.title('LLMèµ‹èƒ½çš„PDFå¯¹è¯Agent ğŸ§‘â€ğŸš€')
    st.info('ä¸Šä¼ PDFæ–‡ä»¶: ')
    pdf = st.file_uploader("ä¸Šä¼ PDFæ–‡ä»¶",type=['pdf'],label_visibility='collapsed')

    # Extract all text from PDF 
    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text=""
        for page in pdf_reader.pages:
            text += page.extract_text()

        # Split text into chunks - ChatGPT cannot process extremely large message history from PDF
        # Have a overlap to ensure context in paragraphs that start from middle of sentences 
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        chunks = text_splitter.split_text(text)

        #Create embeddings ( Vector representations of text ) and store all chunks collection in 1 base
        embeddings = OpenAIEmbeddings()
        info_base = FAISS.from_texts(chunks,embeddings)

        user_question = st.text_input('è¾“å…¥é—®é¢˜: ')
        if user_question:
            # RETRIEVAL AUGMENTED GENERATION
            # Find relevant chunks as per langchain model using similarity search of vectors
            docs = info_base.similarity_search(user_question)
            llm = OpenAI()
            chain = load_qa_chain(llm,chain_type="refine") # Handle question answering tasks 
            with get_openai_callback() as cb:
                response = chain.run(input_documents=docs,question=user_question)
                st.info(f"Completion tokens : {cb.completion_tokens}") # Tokens used
            st.write(response)

##########################################################################################################

# Only if application is run directly ( not imported ), run the code
if __name__ == "__main__":
    main()
